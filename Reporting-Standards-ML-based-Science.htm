<!DOCTYPE html>
<!-- saved from url=(0038)https://reproducible.cs.princeton.edu/ -->
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta http-equiv="Expires" content="0">

  <title>Leakage and the Reproducibility Crisis in ML-based Science</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="./Reporting-Standards-ML-based-Science_files/bootstrap.min.css">
  <script src="./Reporting-Standards-ML-based-Science_files/jquery.min.js.download"></script>
  <script src="./Reporting-Standards-ML-based-Science_files/popper.min.js.download"></script>
  <script src="./Reporting-Standards-ML-based-Science_files/bootstrap.min.js.download"></script>
  <script> $('#myModal').on('shown.bs.modal', function () {
      $('#myInput').trigger('focus')
    })</script>


  <link rel="shortcut icon" href="https://www.cs.princeton.edu/sites/all/themes/pucs_bootstrap/favicon.ico"
    type="image/vnd.microsoft.icon">
  <style>
    .navitems:before {
      height: 60px;
      content: "";
      display: block;
    }

    .centerBlock {
      display: table;
      margin: auto;
    }

    .img-fluid {
      max-width: 100%;
      height: auto;
    }

    .btn-amber {
      color: #000;
      background-color: #f58025;
      border-color: #f58025;
    }
  </style>
</head>

<body style="position: relative; min-height:100vh;" data-spy="scroll" data-offset="15" data-target=".navbar">

  <div class="jumbotron text-center" style="margin-bottom:0">
    <div class="container">
      <div class="row">
        <div style="text-align: left" class="col-sm-1"></div>
        <div class="col-sm-3">
          <div class="col-lg-12">
            <figure class="figure" style="width: 210px;">
              <img class="img-fluid"
                src="./Reporting-Standards-ML-based-Science_files/Princeton_University-Logo.wine.png"
                alt="Princeton University">
            </figure>
          </div>
          <div class="container">
            <div class="col-lg-12">
              <a class="btn btn-amber ml-n1" role="button" href="https://arxiv.org/pdf/2207.07048.pdf"
                style="width: 210px">Draft paper
              </a>
            </div>
          </div>

        </div>
        <div style="text-align: left" class="col-sm-7">
          <h1 style="font-size: 230%">Reporting standards for ML-based science</h1>
          <div style="text-align: left">
            [Insert demoed text here]
          </div>

        </div>
      </div>
    </div>
  </div>

  <nav id="nav-main" class="navbar navbar-expand-sm bg-dark navbar-dark sticky-top mt-n4">
    <div class="mx-auto d-sm-flex d-block flex-sm-nowrap">
      <a class="navbar-brand mr-4" href="#">Top</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsibleNavbar">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="collapsibleNavbar">
        <ul class="nav nav-pills navbar-nav">
          <li class="nav-item mr-3">
            <a class="nav-link" href="#motivation">Motivation</a>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="https://reproducible.cs.princeton.edu/#developing-standards">Developing standards</a>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="https://reproducible.cs.princeton.edu/#checklist">Checklist</a>
          </li>
          <li class="nav-item dropdown mr-4">
            <a class="nav-link dropdown-toggle" href="https://reproducible.cs.princeton.edu/#for-authors" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Potential users
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="https://reproducible.cs.princeton.edu/#for-authors">For authors</a>
              <a class="dropdown-item" href="https://reproducible.cs.princeton.edu/#for-referees">For referees</a>
              <a class="dropdown-item" href="https://reproducible.cs.princeton.edu/#for-journals">For journals</a>
            </div>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="https://reproducible.cs.princeton.edu/#citation">Citation</a>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="https://reproducible.cs.princeton.edu/#about">About us</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <div class="container" style="margin-top:30px; position: relative; height: 100%; ">
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <h4 id="Hypotheses">Context</h4>
      </div>
    </div>
    <div class="row align-items-center">
      <div class="col-sm-1"></div>
      <div class="col-sm-10" style="position: relative;">
        <p>
          <!-- Copied from abstract -->
          Machine learning (ML) methods are proliferating in scientific research. However, the adoption of these methods
          has been accompanied by failures of validity, <a href="https://reproducible.cs.princeton.edu/">reproducibility</a>, and generalizability.

          These failures can hinder scientific progress, lead to false consensus around invalid claims, and can
          undermine the credibility of ML-based science.
        </p>

        <p>
          ML methods are often applied and fail in similar ways across disciplines.

          In this project, we aim to provide clear reporting standards for ML-based science, which take the form of a
          checklist and a paired set of guidelines.

          We developed the reporting standards based on a consensus of 19 researchers across computer science,
          mathematics, social sciences, and health research.
        </p>
      </div>
    </div>
    <div class="row align-items-center">
      <div class="col-sm-1"></div>
      <div class="col-sm-7" style="position: relative;">
        <br><br>
        <h4> Scope </h4>
        <p>We focus on reproducibility issues in ML-based science, which involves making a scientific claim using the
          performance of the ML model as evidence. There is a much better known reproducibility crisis in research that
          uses traditional statistical methods. We also situate our work in contrast to other ML domains, such as
          methods research (creating and improving widely-applicable ML methods), ethics research (studying the ethical
          implications of ML methods), engineering applications (building or improving a product or service), and
          modeling contests (improving predictive performance on a fixed dataset created by an independent third party).
          Investigating the validity of claims in all of these areas is important, and there is ongoing work to address
          reproducibility issues in these domains.</p>
      </div>
      <div class="col-sm-3" style="position: relative;">
        <figure class="figure" style="margin-top: auto; margin-bottom: auto;">
          <img class="img-fluid" style="max-width: 100%; margin-top: auto; margin-bottom: auto; display: block;"
            src="./Reporting-Standards-ML-based-Science_files/ml-based-science.png"
            alt="Various domains in which ML methods are used. In our work, we focus on ML-based science.">
          <figcaption class="figure-caption text-left">
            <p> A non-exhaustive categorization of focus areas in ML literature. In our work, we focus on ML-based
              science.</p>
          </figcaption>
        </figure>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10" style="position: relative;">

        <h4 class="navitems" id="motivation"> Improving reporting standards helps avoid common ML pitfalls </h4>
        <p>
          
        </p>

        <p>
          Data leakage has long been recognized as a leading cause of errors in ML applications. In formative work on
          leakage, <a href="https://dl.acm.org/doi/10.1145/2382577.2382579">Kaufman et al.</a> provide an overview of
          different types of errors and give several recommendations for mitigating these errors. Since this paper was
          published, the ML community has investigated the impact of leakage in <a
            href="https://medium.com/@colin.fraser/the-treachery-of-leakage-56a2d7c4e931">several</a> <a
            href="http://www.rayidghani.com/2020/01/24/top-10-ways-your-machine-learning-models-may-have-leakage/">engineering
            applications</a> and modeling competitions. However, leakage occurring in ML-based science has not been
          comprehensively investigated. As a result, mitigations for data leakage in scientific applications of ML
          remain understudied.
        </p>

        <h4 class="navitems" id="taxonomy"> Towards a solution: A taxonomy of data leakage</h4>

        A taxonomy of data leakage can enable a better understanding of why leakage occurs in ML-based science and
        inform potential solutions. We present a fine-grained taxonomy of 8 types of leakage that range from textbook
        errors to open research problems. Our taxonomy is comprehensive and addresses data leakage arising during the
        data collection, pre-processing, modeling and evaluation steps. In particular, our taxonomy addresses all cases
        of data leakage that we found in our survey. We provide an overview of the types of leakage here, a more
        detailed taxonomy is included in<a href="https://arxiv.org/abs/2207.07048"> our paper</a>.
        <br><br>

        <b>1. Lack of clean separation of training and test set:</b> If the training dataset is not separated from the
        test dataset during all pre-processing, modeling and evaluation steps, the model has access to information in
        the test set before its performance is evaluated.
        <br><br>
        <b>2. Model uses features which are not legitimate:</b> The model has access to features that should not be
        legitimately available for use in the modeling exercise, for instance if they are a proxy for the outcome
        variable.
        <br><br>

        <b>3. Test set is not drawn from the distribution of interest:</b> The distribution of data on which the
        performance of an ML model is evaluated differs from the distribution of data about which the scientific claims
        are made.



        <h4 class="navitems" id="model-info-sheets"> Model info sheets for addressing leakage</h4>
        <p>
          Our taxonomy of data leakage highlights several failure modes which are prevalent in ML-based science. To
          address leakage, researchers using ML methods need to connect the performance of their ML models to their
          scientific claims. To detect cases of leakage, we provide a <a
            href="https://reproducible.cs.princeton.edu/model-info-sheet-template.docx">template</a> for a model info
          sheet which should be included when making a scientific claim using predictive modeling. The template consists
          of precise arguments needed to justify the absence of leakage, and is inspired by <a
            href="https://arxiv.org/abs/1810.03993">Mitchell et al.</a>'s model cards for increasing the transparency of
          ML models.
          <br><br>
          Model info sheets can be voluntarily used by researchers to detect leakage, or journals could encourage or
          require authors to provide them. Of course, model info sheets can’t prevent researchers from making false
          claims, but we hope they can make errors more apparent. Note that for model info sheets to be verified, the
          analysis must be computationally reproducible. Also, model info sheets don’t address reproducibility issues
          other than leakage. The model info sheet template is currently a beta version. We welcome feedback and are
          continuing to make changes to the template based on feedback.
        </p>



        <h4 class="navitems" id="civil-war"> A case study of irreproducibility in civil war prediction </h4>
        <p>
          We find that prominent studies on civil war prediction claiming superior performance of ML models over
          baseline Logistic Regression models fail to reproduce. Our results provide two reasons to be skeptical of the
          use of ML methods in this research area, by both questioning their usefulness and highlighting the pitfalls of
          applying them correctly. While none of these errors could have been caught by reading the papers, our model
          info sheets enable the detection of leakage in each case.
        </p>
        <figure class="figure text-center">
          <img class="img-fluid"
            src="./Reporting-Standards-ML-based-Science_files/allFiveComparisionFigureWithTable.png" style="width:100%"
            alt=" A comparison of reported results vs. corrected results in the 4 papers on civil war prediction that compare the performance of ML models and Logistic Regression models.">
          <figcaption class="figure-caption text-left">
            <p>A comparison of reported and corrected results in civil war prediction papers published in top Political
              Science journals.
              The main findings of each of these papers are invalid due to various forms of data leakage:
              Muchlinski et al. impute the training and test data together, Colaresi &amp; Mahmood and Wang incorrectly
              reuse an imputed dataset, and Kaufman et al. use proxies for the target variable which causes data
              leakage. The use of model info sheets would detect leakage in every paper. When we correct these errors,
              complex ML models (such as Adaboost and Random Forests) do not perform substantively better than
              decades-old Logistic Regression models for civil war prediction in each case. Each column in the table
              outlines the impact of leakage on the results of a paper.
            </p>
          </figcaption>
        </figure>
        <a href="https://codeocean.com/capsule/6282482/tree/v1">Reproduction materials on CodeOcean</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a
          href="https://reproducible.cs.princeton.edu/papers-reviewed.bib"> List of papers in our systematic review </a>
        <br>
        <br>


        <h4 class="navitems" id="terminology"> A note on the term reproducibility crisis </h4>
        <p>
          We acknowledge that there isn't consensus about the term reproducibility, and there have been a number of
          recent attempts to define the term and create consensus. One possible definition is computational
          reproducibility — when the results in a paper can be replicated using the exact code and dataset provided by
          the authors. We argue that this definition is too narrow because even cases of outright bugs in the code would
          not be considered irreproducible under this definition. Therefore we advocate for a standard where bugs and
          other errors in data analysis that change or challenge a paper's findings constitute irreproducibility. We
          elaborate this perspective <a href="https://reproducible.cs.princeton.edu/" data-toggle="modal"
            data-target="#myModal">here</a>.
          <br><br>
          Reproducibility failures don’t mean a claim is wrong, just that evidence presented falls short of the accepted
          standard or that the claim only holds in a narrower set of circumstances than asserted. We don’t view
          reproducibility failures as signs that individual authors or teams are careless, and we don’t think any
          researcher is immune. One of us (Narayanan) has had multiple such failures in his applied-ML work and expects
          that it will probably happen again.
          <br><br>
          We call it a crisis for two related reasons. First, reproducibility failures in ML-based science are systemic.
          In nearly every scientific field that has carried out a systematic study of reproducibility issues, papers are
          plagued by common pitfalls. In many systematic reviews, a majority of the papers reviewed suffer from these
          pitfalls. Second, despite the urgency of addressing reproducibility failures, there aren’t yet any systemic
          solutions.
        </p>

        <h4 class="navitems" id="citation"> Citation </h4>
        To cite this work, please use this <a href="https://reproducible.cs.princeton.edu/citation.bib">BibTeX
          entry</a>.

        <h4 class="navitems" id="about"> About us </h4>
        This is a project by <a href="https://www.cs.princeton.edu/~sayashk/">Sayash Kapoor</a> and <a
          href="https://www.cs.princeton.edu/~arvindn/">Arvind Narayanan</a>. We are researchers in the department of
        computer science and the <a href="https://citp.princeton.edu/">Center for Information Technology Policy</a> at
        Princeton University.
        <br><br>
        Our interest in this topic arose during a <a href="https://msalganik.github.io/cos597E-soc555_f2020/">graduate
          seminar</a> on Limits to Prediction. Narayanan offered this course together with Prof. Matthew Salganik in
        Fall 2020, and Kapoor took the course. The course aimed to critically examine the narrative about the ability to
        predict the future with ever-increasing accuracy given bigger datasets and more powerful algorithms. The work on
        reproducibility pitfalls is one aspect of our broader interest in limits to prediction.
        <br><br>
      </div>
    </div>
  </div>
  <script src="./Reporting-Standards-ML-based-Science_files/bootstrap.bundle.min.js.download"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
    crossorigin="anonymous"></script>


</body>

</html>