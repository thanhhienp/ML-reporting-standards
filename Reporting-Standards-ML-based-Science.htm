<!DOCTYPE html>
<!-- saved from url=(0038)https://reproducible.cs.princeton.edu/ -->
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta http-equiv="Expires" content="0">

  <title>Reporting standards for ML-based science</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="./Reporting-Standards-ML-based-Science_files/bootstrap.min.css">
  <script src="./Reporting-Standards-ML-based-Science_files/jquery.min.js.download"></script>
  <script src="./Reporting-Standards-ML-based-Science_files/popper.min.js.download"></script>
  <script src="./Reporting-Standards-ML-based-Science_files/bootstrap.min.js.download"></script>
  <script> $('#myModal').on('shown.bs.modal', function () {
      $('#myInput').trigger('focus')
    })</script>


  <link rel="shortcut icon" href="https://www.cs.princeton.edu/sites/all/themes/pucs_bootstrap/favicon.ico"
    type="image/vnd.microsoft.icon">
  <style>
    .navitems:before {
      height: 60px;
      content: "";
      display: block;
    }

    .centerBlock {
      display: table;
      margin: auto;
    }

    .img-fluid {
      max-width: 100%;
      height: auto;
    }

    .btn-amber {
      color: #000;
      background-color: #f58025;
      border-color: #f58025;
    }
  </style>
</head>

<body style="position: relative; min-height:100vh;" data-spy="scroll" data-offset="15" data-target=".navbar">

  <div class="jumbotron text-center" style="margin-bottom:0">
    <div class="container">
      <div class="row">
        <div style="text-align: left" class="col-sm-1"></div>
        <div class="col-sm-3">
          <div class="col-lg-12">
            <figure class="figure" style="width: 210px;">
              <img class="img-fluid"
                src="./Reporting-Standards-ML-based-Science_files/Princeton_University-Logo.wine.png"
                alt="Princeton University">
            </figure>
          </div>
          <div class="container">
            <div class="col-lg-12">
              <a class="btn btn-amber ml-n1" role="button" href="https://arxiv.org/pdf/2207.07048.pdf"
                style="width: 210px">Draft paper
              </a>
            </div>
          </div>

        </div>
        <div style="text-align: left" class="col-sm-7">
          <h1 style="font-size: 230%">Reporting standards for ML-based science</h1>
          <div style="text-align: left">
            ML methods are often applied and fail in similar ways across disciplines.

            We aim to provide clear reporting standards for ML-based science, focusing on scientific research and making
            our standard applicable across scientific disciplines.
          </div>

        </div>
      </div>
    </div>
  </div>

  <nav id="nav-main" class="navbar navbar-expand-sm bg-dark navbar-dark sticky-top mt-n4">
    <div class="mx-auto d-sm-flex d-block flex-sm-nowrap">
      <a class="navbar-brand mr-4" href="#">Top</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsibleNavbar">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="collapsibleNavbar">
        <ul class="nav nav-pills navbar-nav">
          <li class="nav-item mr-3">
            <a class="nav-link" href="#motivation">Motivation</a>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="#process">Process</a>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="#standards">Reporting standards</a>
          </li>
          <li class="nav-item dropdown mr-4">
            <a class="nav-link dropdown-toggle" href="" id="navbarDropdown" role="button" data-toggle="dropdown"
              aria-haspopup="true" aria-expanded="false">
              Potential users
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="#for-authors">For authors</a>
              <a class="dropdown-item" href="#for-referees">For referees</a>
              <a class="dropdown-item" href="#for-journals">For journals</a>
            </div>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="https://reproducible.cs.princeton.edu/#citation">Citation</a>
          </li>
          <li class="nav-item mr-4">
            <a class="nav-link" href="https://reproducible.cs.princeton.edu/#about">About us</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <div class="container" style="margin-top:30px; position: relative; height: 100%; ">
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <h4 id="Hypotheses">Context</h4>
      </div>
    </div>
    <div class="row align-items-center">
      <div class="col-sm-1"></div>
      <div class="col-sm-10" style="position: relative;">
        <p>
          ML methods are being widely adopted for scientific research.

          Compared to older statistical methods, they offer increased predictive accuracy, the ability to process large
          amounts of data, and the ability to use different types of data for scientific research, such as text, images,
          and video.

          However, the rapid uptake of ML methods has been accompanied by concerns of validity, <a
            href="https://reproducible.cs.princeton.edu/">reproducibility</a>, and generalizability.

          These failures can hinder scientific progress, lead to false consensus around invalid claims, and can
          undermine the credibility of ML-based science.
        </p>

        <p>
          ML methods are often applied and fail in similar ways across disciplines.

          In this project, we aim to provide clear reporting standards for ML-based science, which take the form of a
          checklist and a paired set of guidelines.

          We developed the reporting standards based on a consensus of 19 researchers across computer science,
          mathematics, social sciences, and health research.
        </p>
      </div>
    </div>
    <div class="row align-items-center">
      <div class="col-sm-1"></div>
      <div class="col-sm-7" style="position: relative;">
        <br><br>
        <h4> Scope </h4>
        <p>
          We focus on reproducibility issues in ML-based science, which involves making a scientific claim using the
          performance of the ML model as evidence.

          For example, Salganik et al. use ML methods to investigate the predictability of life outcomes.
        </p>
        <p>
          This is in contrast to ML methods research, which involves improving ML methods that are widely applicable
          instead of making scientific claims using ML methods.
        </p>
        <p>
          There is a much better known reproducibility crisis in research that uses traditional statistical methods.
        </p>
      </div>
      <div class="col-sm-3" style="position: relative;">
        <figure class="figure" style="margin-top: auto; margin-bottom: auto;">
          <img class="img-fluid" style="max-width: 100%; margin-top: auto; margin-bottom: auto; display: block;"
            src="./Reporting-Standards-ML-based-Science_files/ml-based-science.png"
            alt="Various domains in which ML methods are used. In our work, we focus on ML-based science.">
          <figcaption class="figure-caption text-left">
            <p> A non-exhaustive categorization of focus areas in ML literature. In our work, we focus on ML-based
              science.</p>
          </figcaption>
        </figure>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10" style="position: relative;">

        <h4 class="navitems" id="motivation"> Improving reporting standards helps avoid common ML pitfalls </h4>


        <p>
          Clear expectations for using ML methods can allow researchers and referees to spot issues early.
        </p>
        <p>
          Despite the use of ML methods across disciplines, there are no widely applicable best practices for reporting
          the design, implementation, and evaluation of ML-based science.

          This leads to different, and often no fixed reporting standards in each field adopting ML methods.

          As a result, common failure modes in using ML methods recur across disciplines.
        </p>

        <p>
          The goal of this paper is to set reporting standards for ML-based science.

          To that end, we develop a checklist and guidelines for reporting ML-based science.
        </p>

        <div id="accordion">
          <div class="card m-1">
            <div class="card-header" id="headingOne">
              <h5 class="mb-0">
                <button class="btn btn-link" data-toggle="collapse" data-target="#collapseOne" aria-expanded="false"
                  aria-controls="collapseOne">
                  <b>Why a Checklist?</b>
                </button>
              </h5>
            </div>

            <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accordion">
              <div class="card-body">
                <p>
                  Checklists have been adopted in many scientific fields, and they have been impactful in improving
                  reporting practices.
                </p>
                <p>
                  In 2014, the NIH created principles to improve reproducibility and rigor, endorsed by several
                  journals.

                  One item was the creation of reporting standards and checklists for journals.
                </p>
                <p>
                  The EQUATOR network, which collects reporting guidelines for health research, includes over 500
                  checklists.
                </p>
                <p>
                  Several checklists have been proposed in ML methods research.
                </p>
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="headingTwo">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseTwo"
                  aria-expanded="false" aria-controls="collapseTwo">
                  <b>What's New?</b>
                </button>
              </h5>
            </div>
            <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordion">
              <div class="card-body">
                <p>
                  Our reporting standards differ from this large body of past work in two crucial ways.
                </p>
                <p>
                  First, we aimed to make our reporting standards field-agnostic, so that they can be used by
                  researchers
                  across fields.

                  We selected items that broadly apply to fields that use ML methods.
                </p>
                <p>
                  Second, past checklists for ML methods research focus on reproducibility issues that arise commonly
                  when
                  developing ML methods.

                  But these issues differ from the ones that arise in scientific research.
                </p>
                <p>
                  Still, past work in both scientific research and ML methods research has helped inform our checklist.
                </p>
              </div>
            </div>
          </div>
        </div>

        <h4 class="navitems" id="process"> Process for developing the reporting standards </h4>
        <p>
          Our initial draft of the checklist consisted of items necessary in a canonical ML pipeline.

          We focused on two aspects of the pipeline:
        </p>
        <p>
          <b>(1) Best practices</b> for building ML models that are common to ML-based science.

          This can help researchers ensure that their process for building ML models is transparent and an independent
          researcher can easily understand it.
        </p>
        <p>
          <b>(2) Common pitfalls</b> in their adoption.

          This allows researchers and referees spot and fix widespread errors in ML-based science.
        </p>
        <p>
          We also draw from previous efforts at improving the reporting quality of ML.

          In particular, we use three past checklists to ensure our coverage of important items in reporting an ML
          model.
        </p>
        <p>
          1. Pineau et al. provide the checklist used alongside papers submitted to NeurIPS 2020, a prominent ML methods
          conference.
        </p>
        <p>
          2. Collins et al. provide the <i>TRIPOD</i> checklist for prediction models in health research.
        </p>
        <p>
          3. Mongan et al. provide the <i>CLAIM</i> checklist for AI models in clinical imaging.
        </p>
        <p>
          We chose these checklists because they cover diverse modeling approaches and are applicable in different
          settings (ML methods research, models for individual diagnosis and prognosis, and ML for medical imaging,
          respectively).
        </p>
        <p>
          Once we had an initial set of items, authors met virtually for a discussion.

          Then, the authors collaboratively edited the checklist to choose commonly applicable items across
          disciplines.

          Finally, the authors independently flagged items that were unclear to improve the quality of the
          reporting standards.
        </p>

        <h4 class="navitems" id="standards"> Reporting standards for ML-based science</h4>
        <p>
          Our checklist consists of 35 items across 8 sections.

          <a href="">See the full checklist.</a>
        </p>
        <p>
          Our guidelines accompanies the checklist.

          For each <i>item</i>, we include expectations about what it means to address the item sufficiently.

          To aid researchers new to ML-based science, each item guidelines also identify resources and relevant past
          literature.

          <a href="">See the full guidelines.</a>
        </p>
        <p>
          Below, we briefly discuss each section of the reporting standards.
        </p>

        <div id="accordion">
          <div class="card m-1">
            <div class="card-header" id="sectionOne">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingOne"
                  aria-expanded="false" aria-controls="collapseHeadingOne">
                  Study design
                </button>
              </h5>
            </div>

            <div id="collapseHeadingOne" class="collapse" aria-labelledby="sectionOne" data-parent="#accordion">
              <div class="card-body">
                ML-based science has many researcher degrees of freedom.

                Each design decision can significantly impact the conclusions drawn from a study.

                This section focuses on clearly and precisely stating the decisions taken during a study's design.

                This is motivated by recent research which shows that reporting these decisions in adequate depth and
                clarity is not trivial or common.

                For instance, Lundberg et al. find that none of the quantitative papers published in a top sociology
                journal in 2018 report their estimands in sufficient detail.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionTwo">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingTwo"
                  aria-expanded="false" aria-controls="collapseTwo">
                  Computational reproducibility
                </button>
              </h5>
            </div>
            <div id="collapseHeadingTwo" class="collapse" aria-labelledby="sectionTwo" data-parent="#accordion">
              <div class="card-body">
                This refers to the ability of an independent researcher to get the same results that are reported in a
                paper or manuscript.

                Computational reproducibility allows errors to be uncovered quickly.

                Independent researchers can verify and build on a study's results.

                Despite being a core tenet of computational research, it is hard to achieve computational
                reproducibility in practice.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionThree">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingThree"
                  aria-expanded="false" aria-controls="collapseThree">
                  Data quality
                </button>
              </h5>
            </div>
            <div id="collapseHeadingThree" class="collapse" aria-labelledby="sectionThree" data-parent="#accordion">
              <div class="card-body">
                This section helps readers and referees understand and evaluate the quality of the data used in the
                study.

                Using poor quality data or data that is not suitable for answering a research question can lead to
                results that are meaningless or misleading.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionFour">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingFour"
                  aria-expanded="false" aria-controls="collapseFour">
                  Data preprocessing
                </button>
              </h5>
            </div>
            <div id="collapseHeadingFour" class="collapse" aria-labelledby="sectionFour" data-parent="#accordion">
              <div class="card-body">
                Different preprocessing steps can lead to vastly different outcomes from the modeling process.

                Even small changes, such as changing the order in which the data preparation steps take place, can lead
                to large differences in outcomes.

                For example, Vandewiele et al. find that oversampling before splitting the data into training and
                evaluation sets lead to widespread errors in pre-term birth detection.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionFive">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingFive"
                  aria-expanded="false" aria-controls="collapseFive">
                  Modeling
                </button>
              </h5>
            </div>
            <div id="collapseHeadingFive" class="collapse" aria-labelledby="sectionFive" data-parent="#accordion">
              <div class="card-body">
                There are many steps involved in developing an ML model.

                This makes it hard to report exact details about the model, and can hinder replication by independent
                researchers.

                For example, Raff found that ML results can often not be replicated using the paper's text (i.e.,
                without using the code accompanying a paper).

                We ask authors to specify the main steps in the modeling process, including feature selection, the types
                of models considered, and evaluation.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionSix">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingSix"
                  aria-expanded="false" aria-controls="collapseSix">
                  Data leakage
                </button>
              </h5>
            </div>
            <div id="collapseHeadingSix" class="collapse" aria-labelledby="sectionSix" data-parent="#accordion">
              <div class="card-body">
                Leakage is a spurious relationship between the independent variables and the target variable that arises
                as an artifact of the data collection, sampling, preprocessing, or modeling steps.

                For example, normalizing features in the training and test data together leads to leakage since
                information about the test data features is included in the training data.

                Leakage is a major source of reproducibility failures: it affects dozens of fields and hundreds of
                published papers and can lead to vastly overoptimistic results.

                We ask authors to justify that their study does not suffer from the main sources of leakage.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionSeven">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingSeven"
                  aria-expanded="false" aria-controls="collapseSeven">
                  Metrics and uncertainty quantification
                </button>
              </h5>
            </div>
            <div id="collapseHeadingSeven" class="collapse" aria-labelledby="sectionSeven" data-parent="#accordion">
              <div class="card-body">
                The performance of ML models is key to the scientific claims of interest.

                Since there are many possible choices authors can make when choosing metrics, it is important to reason
                why the metrics used are appropriate for the task at hand.

                Communicating and reasoning about uncertainty is critical.

                Still, Simmonds et al. find that studies often do not report the various kinds of uncertainty in the
                modeling process.

                We ask authors to report the metrics and uncertainty estimates used in enough detail to enable a
                judgment about whether they made valid choices for evaluating the performance of the model and drawing
                scientific inferences.
              </div>
            </div>
          </div>
          <div class="card m-1">
            <div class="card-header" id="sectionEight">
              <h5 class="mb-0">
                <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseHeadingEight"
                  aria-expanded="false" aria-controls="collapseEight">
                  Generalizability
                </button>
              </h5>
            </div>
            <div id="collapseHeadingEight" class="collapse" aria-labelledby="sectionEight" data-parent="#accordion">
              <div class="card-body">
                ML-based science faces a number of threats to external validity.

                Since studies that use ML methods are often unaccompanied by external (i.e., true out-of-sample)
                validation, it is important to reason about these threats.

                Additionally, authors are best positioned to identify the boundaries of applicability of their claims in
                order to prevent misunderstandings about the claims made in their study.
              </div>
            </div>
          </div>
        </div>

        <h4 class="navitems" id="for-authors"> How authors can use the reporting standards </h4>
        <p>
          <b>Authors</b> can self-regulate by using the reporting standards to identify errors and preemptively address
          concerns about the use of ML methods in their paper.

          This can also help increase the credibility of their paper, especially in fields that are newly adopting ML
          methods.
        </p>
        <p>
          We expect the reporting standards to be useful to authors throughout the study - during conceptualization,
          implementation, and communication of the results.
        </p>
        <p>
          The checklist can be included as part of the supplementary materials released alongside a paper, such as the
          code and data.
        </p>
        <p>
          The guidelines can help authors learn how to correctly apply our reporting standards in their own work and
          introduce them to underlying theories of evidence.
        </p>

        <h4 class="navitems" id="for-referees"> How referees can use the reporting standards </h4>
        <p>
          <b>Referees</b> can use the reporting standards to determine whether a study they are reviewing falls short.
        </p>
        <p>
          If they have concerns about a study, they can ask researchers to include the filled out checklist in a revised
          version.

          For example, Roberts et al. use the CLAIM checklist to filter papers for a systematic review based on
          compliance with the checklist.
        </p>
        <h4 class="navitems" id="for-journals"> How journals can use the reporting standards </h4>
        <p>
          <b>Journals</b> can require authors to submit a checklist along with their papers to set reporting standards
          for ML-based science.

          Similar checklists are in place in a number of journals; however, they are usually used for specific
          disciplines rather than for methods that are prevalent across disciplines.

          Since ML-based science is proliferating across disciplines, our reporting standards offer a method-specific
          (rather than discipline-specific) intervention.
        </p>

        <h4 class="navitems" id="citation"> Citation </h4>
        To cite this work, please use this <a href="">BibTeX entry</a>. [BibTex not linked]

        <h4 class="navitems" id="about"> About us </h4>
        [Placeholder for details about authors, from a variety of backgrounds and experiences]
        <br><br>
      </div>
    </div>
  </div>
  <script src="./Reporting-Standards-ML-based-Science_files/bootstrap.bundle.min.js.download"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
    crossorigin="anonymous"></script>


</body>

</html>